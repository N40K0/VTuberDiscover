{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N40K0/VtuberDiscover/blob/main/VtuberDiscovery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YysnF3a5W8aK",
        "outputId": "69378e05-cc63-4f96-f13c-77d4f0b729fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UyMCHd3KbZIy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPIBQsVu8ki"
      },
      "source": [
        "# **Creating Functions**\n",
        "- CreateData \n",
        "- trainModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vb1uMnm9xC6T"
      },
      "outputs": [],
      "source": [
        "def createData(pathToDataset: str, imageSize: tuple, trainDataGenerator:ImageDataGenerator,\n",
        "               valDataGenerator:ImageDataGenerator = ImageDataGenerator(rescale=1./255), \n",
        "               batchSize:int = 32, classMode = \"sparse\"):\n",
        "    \n",
        "    validationData = valDataGenerator.flow_from_directory(\n",
        "        pathToDataset,\n",
        "        target_size = imageSize,\n",
        "        class_mode = classMode,\n",
        "        seed = 123\n",
        "    )\n",
        "\n",
        "    trainingData = trainDataGenerator.flow_from_directory(\n",
        "        pathToDataset,\n",
        "        target_size = imageSize,\n",
        "        class_mode = classMode,\n",
        "        seed = 123\n",
        "    )\n",
        "\n",
        "    return trainingData, validationData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0jOnzf6xrlcz"
      },
      "outputs": [],
      "source": [
        "def trainingConfig(model ,trainingData, validationData, epochs, verbose, initialEpoch):\n",
        "    checkPoint = keras.callbacks.ModelCheckpoint(\n",
        "        \"/content/CheckPoint\", monitor='val_accuracy', save_best_only=True,\n",
        "        mode='auto', save_freq='epoch', save_weights_only=True\n",
        "    )\n",
        "\n",
        "    return model.fit(\n",
        "        trainingData,\n",
        "        validation_data = validationData,\n",
        "        epochs = epochs,\n",
        "        initial_epoch = initialEpoch,\n",
        "        callbacks = [checkPoint],\n",
        "        verbose = verbose\n",
        "    )\n",
        "\n",
        "def trainModel(model:Model, trainingData, validationData, epochs = 11, verbose = 2, initialEpoch = 0):\n",
        "    if tf.test.gpu_device_name() != '/device:GPU:0': \n",
        "        return trainingConfig(model, trainingData, validationData, epochs, verbose, initialEpoch)\n",
        "    else:\n",
        "        with tf.device(\"/device:GPU:0\"):\n",
        "            return trainingConfig(model, trainingData, validationData, epochs, verbose, initialEpoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33-j_Q5Mlk52"
      },
      "source": [
        "# **Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmx5LznDljbh"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/Vtubers\n",
        "!cp /content/drive/MyDrive/Asset/Model/Datasets/VtuberDataset.tar.gz /content\n",
        "!tar -xf /content/VtuberDataset.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eokxYNFAUL7o"
      },
      "outputs": [],
      "source": [
        "imageSize = (224, 224)\n",
        "inputShape = (imageSize[0], imageSize[1], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9S8a7Dd_ZtZo"
      },
      "outputs": [],
      "source": [
        "DataGenerator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    # width_shift_range= 0.2,\n",
        "    # height_shift_range= 0.2,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip= True,\n",
        "    zoom_range = 0.3,\n",
        "    rotation_range = 20,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jxXbxgeYmkH",
        "outputId": "433a80cf-8ffe-42af-fc87-a68194e70880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1446 images belonging to 5 classes.\n",
            "Found 1446 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "trainingData, validationData = createData(\n",
        "    trainDataGenerator = DataGenerator, \n",
        "    pathToDataset = \"/content/Vtubers\", \n",
        "    imageSize = imageSize,\n",
        "    classMode = \"sparse\" \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4hztf7rRoLM"
      },
      "source": [
        "# Creating Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4rAaVNPZfHP",
        "outputId": "ec4faecb-68bf-4a24-b4e1-42b7aa5e6973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 222, 222, 128)     3584      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 222, 222, 128)     0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 111, 111, 128)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 109, 109, 256)     295168    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 109, 109, 256)     0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 54, 54, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 52, 52, 512)       1180160   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 52, 52, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 26, 26, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 26, 26, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,271,493\n",
            "Trainable params: 2,270,469\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.InputLayer(input_shape = inputShape),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), padding=\"valid\", activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "    layers.Conv2D(256, (3,3), padding=\"valid\", activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "    layers.Conv2D(512, (3,3), padding=\"valid\", activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "    layers.Normalization(),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dropout(0.8),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(len(trainingData.class_indices), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LtSfXeQZQw0"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk_37bP1eWuN"
      },
      "source": [
        "# Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h8CPKEFeY-u",
        "outputId": "3369e7a5-2829-457f-8aad-9d166c0653c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "46/46 [==============================] - 38s 800ms/step - loss: 1.1037 - accuracy: 0.6100 - val_loss: 1.4937 - val_accuracy: 0.8181\n",
            "Epoch 2/15\n",
            "46/46 [==============================] - 37s 801ms/step - loss: 0.5104 - accuracy: 0.8250 - val_loss: 1.3689 - val_accuracy: 0.5519\n",
            "Epoch 3/15\n",
            "46/46 [==============================] - 37s 793ms/step - loss: 0.3053 - accuracy: 0.8928 - val_loss: 1.2977 - val_accuracy: 0.4564\n",
            "Epoch 4/15\n",
            "46/46 [==============================] - 36s 801ms/step - loss: 0.1699 - accuracy: 0.9502 - val_loss: 1.1123 - val_accuracy: 0.5463\n",
            "Epoch 5/15\n",
            "46/46 [==============================] - 37s 789ms/step - loss: 0.0693 - accuracy: 0.9820 - val_loss: 0.9517 - val_accuracy: 0.7040\n",
            "Epoch 6/15\n",
            "46/46 [==============================] - 37s 796ms/step - loss: 0.0596 - accuracy: 0.9841 - val_loss: 0.6469 - val_accuracy: 0.8976\n",
            "Epoch 7/15\n",
            "46/46 [==============================] - 37s 791ms/step - loss: 0.0540 - accuracy: 0.9786 - val_loss: 0.5587 - val_accuracy: 0.7607\n",
            "Epoch 8/15\n",
            "46/46 [==============================] - 37s 794ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.4678 - val_accuracy: 0.8451\n",
            "Epoch 9/15\n",
            "46/46 [==============================] - 37s 792ms/step - loss: 0.0947 - accuracy: 0.9682 - val_loss: 0.2591 - val_accuracy: 0.9537\n",
            "Epoch 10/15\n",
            "46/46 [==============================] - 37s 795ms/step - loss: 0.0418 - accuracy: 0.9876 - val_loss: 0.2521 - val_accuracy: 0.9440\n",
            "Epoch 11/15\n",
            "46/46 [==============================] - 37s 806ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 0.2094 - val_accuracy: 0.9599\n",
            "Epoch 12/15\n",
            "46/46 [==============================] - 36s 789ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.2369 - val_accuracy: 0.9253\n",
            "Epoch 13/15\n",
            "46/46 [==============================] - 37s 791ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.3737 - val_accuracy: 0.8838\n",
            "Epoch 14/15\n",
            "46/46 [==============================] - 37s 795ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0476 - val_accuracy: 0.9834\n",
            "Epoch 15/15\n",
            "46/46 [==============================] - 37s 793ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.3321 - val_accuracy: 0.8790\n"
          ]
        }
      ],
      "source": [
        "history = trainModel(model, trainingData, validationData, epochs=15, verbose=1, initialEpoch=0)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI1U9igK3_pz"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyNtJ4T47S7G"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMHt1WHY2vOY",
        "outputId": "0f931ffb-7a1c-4c02-c7d8-fcff213607ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Sample/Kana1.jpg\n",
            "Predicion result 73.11% indicate as Kamiko_Kana [1]\n",
            "with file name = Kana1.jpg\n",
            "\n",
            "/content/Sample/Kana3.jpg\n",
            "Predicion result 73.10% indicate as Kamiko_Kana [1]\n",
            "with file name = Kana3.jpg\n",
            "\n",
            "/content/Sample/Kane1.png\n",
            "Predicion result 73.11% indicate as Kaneko_hato [2]\n",
            "with file name = Kane1.png\n",
            "\n",
            "/content/Sample/Kane2.png\n",
            "Predicion result 73.11% indicate as Kaneko_hato [2]\n",
            "with file name = Kane2.png\n",
            "\n",
            "/content/Sample/Prune1.png\n",
            "Predicion result 72.50% indicate as Prune [3]\n",
            "with file name = Prune1.png\n",
            "\n",
            "/content/Sample/Prune2.png\n",
            "Predicion result 66.40% indicate as Kamiko_Kana [1]\n",
            "with file name = Prune2.png\n",
            "\n",
            "/content/Sample/corryn1.png\n",
            "Predicion result 72.59% indicate as Suzune_corryn [4]\n",
            "with file name = corryn1.png\n",
            "\n",
            "/content/Sample/corryn2.png\n",
            "Predicion result 71.89% indicate as Suzune_corryn [4]\n",
            "with file name = corryn2.png\n",
            "\n",
            "/content/Sample/corryn3.png\n",
            "Predicion result 72.50% indicate as Suzune_corryn [4]\n",
            "with file name = corryn3.png\n",
            "\n",
            "/content/Sample/ethel1.png\n",
            "Predicion result 72.98% indicate as Ethel_chamomile [0]\n",
            "with file name = ethel1.png\n",
            "\n",
            "/content/Sample/ethel2.png\n",
            "Predicion result 73.10% indicate as Ethel_chamomile [0]\n",
            "with file name = ethel2.png\n",
            "\n",
            "/content/Sample/ethel3.png\n",
            "Predicion result 73.10% indicate as Ethel_chamomile [0]\n",
            "with file name = ethel3.png\n",
            "\n",
            "/content/Sample/kana1.png\n",
            "Predicion result 73.08% indicate as Kamiko_Kana [1]\n",
            "with file name = kana1.png\n",
            "\n",
            "/content/Sample/kana2.jpg\n",
            "Predicion result 73.11% indicate as Kamiko_Kana [1]\n",
            "with file name = kana2.jpg\n",
            "\n",
            "/content/Sample/kana4.png\n",
            "Predicion result 73.10% indicate as Kamiko_Kana [1]\n",
            "with file name = kana4.png\n",
            "\n",
            "/content/Sample/kane3.png\n",
            "Predicion result 73.10% indicate as Kaneko_hato [2]\n",
            "with file name = kane3.png\n",
            "\n",
            "/content/Sample/prune3.png\n",
            "Predicion result 69.88% indicate as Ethel_chamomile [0]\n",
            "with file name = prune3.png\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -rf ./Sample/.ipynb_checkpoints/\n",
        "import os\n",
        "\n",
        "imgProcessing = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 20\n",
        ")\n",
        "\n",
        "# checkPoint = model.load_weights(\"/content/CheckPoint/variables/variables.index\")\n",
        "dir = \"/content/Sample\"\n",
        "samples = os.listdir(dir)\n",
        "samples.sort()\n",
        "\n",
        "newLabels = {'Ethel_chamomile': 0, 'Kamiko_Kana': 1, \"Kaneko_hato\": 2, \"Prune\": 3, \"Suzune_corryn\": 4}\n",
        "labelValue = list(newLabels.values())\n",
        "labelName = list(newLabels.keys())\n",
        "\n",
        "# print(newLabels)\n",
        "for sample in samples:\n",
        "    path = os.path.join(dir, sample)\n",
        "    print(path)\n",
        "\n",
        "    loadedImg = load_img(path, target_size = imageSize)\n",
        "    imgBatch = tf.expand_dims(img_to_array(loadedImg), 0, sample)\n",
        "    img = imgProcessing.flow(imgBatch)\n",
        "\n",
        "    result = model.predict(img)\n",
        "    prediction = tf.nn.sigmoid(result[0])\n",
        "    score = np.argmax(prediction)\n",
        "\n",
        "    predictionResult = labelValue.index(score)\n",
        "    print(f\"Predicion result {prediction[score]*100:0.2f}% indicate as {labelName[predictionResult]} [{score}]\")\n",
        "    print(f\"with file name = {sample}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2kwAfAC4FpZ"
      },
      "outputs": [],
      "source": [
        "model.save(\"./912022_v2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAMIyixzHN4v",
        "outputId": "4eb82b1e-3de3-4778-8a71-30e44d4bd03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed tensorflowjs-3.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./tmp\n",
        "!tensorflowjs_converter --input_format keras --output_format=tfjs_graph_model \"/content/912022_v2.h5\" \"/content/tmp\"\n",
        "!!zip -r /content/discoverVtuberGraph-0.1.0.zip /content/tmp/"
      ],
      "metadata": {
        "id": "gs4p5u_5G585"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VtuberDiscovery.ipynb",
      "provenance": [],
      "mount_file_id": "1mJN5Y_itDy27nO7wz9ldOHZ2KJ5hZlN6",
      "authorship_tag": "ABX9TyNlcS3c14xZlogXssp8RhXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}